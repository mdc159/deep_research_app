# Deep Research App

A Python research system that transforms PDFs, URLs, and research questions into **versioned, citation-backed Markdown papers** using the `deepagents` framework with a Streamlit UI.

## Features

- **PDF + URL Ingestion**: Structure-aware chunking with Docling and crawl4ai
- **Hybrid Search**: Vector + keyword search with RRF fusion and CrossEncoder reranking
- **Contextual Embeddings**: LLM-enhanced embeddings for improved retrieval
- **Evidence-First Drafting**: Claims linked to evidence or marked as assumptions
- **Citation Management**: IEEE-style references with source provenance
- **Version Control**: Document versioning with change logs and diffs
- **Model Flexibility**: Swap models per pipeline stage via configuration

## Quick Start

### Prerequisites

- Python 3.12+
- [Astral UV](https://github.com/astral-sh/uv) package manager
- Supabase account (or local PostgreSQL with pgvector)

### Installation

```bash
# Clone and navigate to the project
cd deep_research_app

# Create virtual environment with UV
uv venv

# Activate the environment
source .venv/bin/activate  # Unix/macOS
# or
.venv\Scripts\activate     # Windows

# Install dependencies
uv sync
```

### Configuration

1. Copy the environment template:
   ```bash
   cp .env.example .env
   ```

2. Fill in your API keys in `.env`:
   - `ANTHROPIC_API_KEY` - For Claude models
   - `OPENAI_API_KEY` - For embeddings
   - `SUPABASE_URL` and `SUPABASE_SERVICE_KEY` - For database
   - `TAVILY_API_KEY` - For web search

3. Apply database migrations to Supabase:
   - Go to your Supabase project's SQL Editor
   - Run the contents of `migrations/001_init.sql`

### Running the App

```bash
# Start the Streamlit app
uv run streamlit run app/streamlit_app.py
```

## Project Structure

```
deep_research_app/
â”œâ”€â”€ app/                    # Streamlit UI
â”‚   â”œâ”€â”€ streamlit_app.py    # Main entry point
â”‚   â””â”€â”€ ui/                 # UI components
â”œâ”€â”€ research_agent/         # Agent pipeline
â”‚   â”œâ”€â”€ agent.py            # create_research_agent()
â”‚   â”œâ”€â”€ prompts.py          # System prompts
â”‚   â”œâ”€â”€ tools/              # Agent tools
â”‚   â””â”€â”€ middleware/         # Custom middleware
â”œâ”€â”€ ingestion/              # PDF/URL processing
â”œâ”€â”€ retrieval/              # Hybrid search
â”œâ”€â”€ storage/                # Supabase operations
â”œâ”€â”€ schemas/                # Pydantic models
â”œâ”€â”€ migrations/             # SQL migrations
â””â”€â”€ tests/                  # Test suite
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      STREAMLIT UI                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Left Pane            â”‚ Right Pane                           â”‚
â”‚ - Run Manager        â”‚ - Document Composer                  â”‚
â”‚ - Evidence Browser   â”‚   [Preview] [Edit] [Diff]            â”‚
â”‚ - Run Log            â”‚ - Citation Inspector                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DEEPAGENTS ORCHESTRATOR                     â”‚
â”‚  â”œâ”€â”€ TodoListMiddleware (planning)                          â”‚
â”‚  â”œâ”€â”€ IngestionMiddleware (PDF/URL processing)               â”‚
â”‚  â”œâ”€â”€ RetrievalMiddleware (hybrid search)                    â”‚
â”‚  â”œâ”€â”€ CitationMiddleware (evidence linking)                  â”‚
â”‚  â””â”€â”€ CritiqueMiddleware (quality checks)                    â”‚
â”‚                                                              â”‚
â”‚  Subagents: researcher, drafter, critic                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA LAYER                              â”‚
â”‚  Supabase Postgres + pgvector + tsvector                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Usage

### Creating a Research Run

1. In the sidebar, expand "â• New Research Run" and enter a **Title** and **Research Objective**
2. Click **Create Run** to load the Run, Evidence, and Log tabs for that run
3. In the **ğŸ“„ Run** tab, add sources via **Upload PDFs** or **Add URLs**
4. Once sources are added, click **â–¶ï¸ Start Research** in the **ğŸ¤– Research Agent** section to kick off the workflow

### Workflow

1. **Plan**: Agent creates a todo list for the research
2. **Ingest**: PDFs/URLs are chunked and embedded
3. **Research**: Evidence is gathered via hybrid search
4. **Draft**: Sections are written with inline citations
5. **Cite**: Citations are resolved to numbered references
6. **Critique**: Quality checks identify issues
7. **Revise**: Issues are addressed, creating new version

## Development

### Running Tests

```bash
uv run pytest tests/ -v
```

### Code Formatting

```bash
uv run black .
uv run ruff check --fix .
```

### Type Checking

```bash
uv run mypy .
```

## License

MIT

## Acknowledgments

Built with:
- [deepagents](https://github.com/deepagents/deepagents) - Agent framework
- [LangChain](https://langchain.com/) - LLM abstraction
- [Docling](https://github.com/DS4SD/docling) - PDF extraction
- [crawl4ai](https://github.com/unclecode/crawl4ai) - Web content fetching
- [Supabase](https://supabase.com/) - Database and vector storage
- [Streamlit](https://streamlit.io/) - UI framework
