# =============================================================================
# DEEP RESEARCH APP - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your API keys
# Never commit .env to version control!

# =============================================================================
# LLM Providers
# =============================================================================

# Anthropic (Claude) - Primary provider for research agents
ANTHROPIC_API_KEY=sk-ant-...

# OpenAI - For embeddings and optional GPT models
OPENAI_API_KEY=sk-...

# Google (Gemini) - Optional alternative provider
GOOGLE_API_KEY=...

# OpenRouter - Optional for additional model access
OPENROUTER_API_KEY=...

# =============================================================================
# Supabase Configuration
# =============================================================================

# Supabase project URL
SUPABASE_URL=https://your-project.supabase.co

# Supabase anon key (for client-side access)
SUPABASE_KEY=eyJ...

# Supabase service role key (for server-side admin operations)
SUPABASE_SERVICE_KEY=eyJ...

# =============================================================================
# Search Configuration
# =============================================================================

# Tavily API key for web search
TAVILY_API_KEY=tvly-...

# =============================================================================
# Model Configuration
# =============================================================================

# Default models for each pipeline stage (can be overridden per-run)
# Format: provider:model_name

# Planner model (orchestrates the research workflow)
PLANNER_MODEL=anthropic:claude-sonnet-4-5-20250929

# Drafter model (writes research content)
DRAFTER_MODEL=anthropic:claude-sonnet-4-5-20250929

# Critic model (reviews and critiques drafts)
CRITIC_MODEL=anthropic:claude-sonnet-4-5-20250929

# Embedding model (for vector search)
EMBEDDING_MODEL=text-embedding-3-small

# Contextualizer model (for contextual embeddings, optional)
CONTEXTUALIZER_MODEL=anthropic:claude-haiku-3

# =============================================================================
# Ingestion Configuration
# =============================================================================

# Enable contextual embeddings (improves retrieval quality, uses more tokens)
USE_CONTEXTUAL_EMBEDDINGS=true

# Chunk size in tokens
CHUNK_SIZE_TOKENS=1000

# Chunk overlap in tokens
CHUNK_OVERLAP_TOKENS=200

# =============================================================================
# Retrieval Configuration
# =============================================================================

# Search type: hybrid, vector, or keyword
SEARCH_TYPE=hybrid

# Vector search weight (0.0 to 1.0)
VECTOR_WEIGHT=0.6

# Keyword search weight (0.0 to 1.0)
KEYWORD_WEIGHT=0.4

# RRF constant (typically 60)
RRF_K=60

# Enable reranking with CrossEncoder
USE_RERANKING=true

# Reranker model
RERANKER_MODEL=ms-marco-MiniLM-L-6-v2

# =============================================================================
# Application Settings
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Streamlit server port
STREAMLIT_PORT=8501

# =============================================================================
# Optional: Redis Cache (for faster repeated searches)
# =============================================================================

# REDIS_URL=redis://localhost:6379

# =============================================================================
# Optional: LangSmith (for debugging and observability)
# =============================================================================

# LANGSMITH_API_KEY=...
# LANGSMITH_PROJECT=deep-research-app
